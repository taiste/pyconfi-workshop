\documentclass[13pt,xcolor=dvipsnames]{beamer}
\usepackage[utf8]{inputenc}
\usepackage{palatino}
\usepackage{listings}
\usecolortheme[named=Black]{structure}
\usefonttheme{serif}
\usetheme{Pittsburgh}

\title{Going Concurrent with Python}
\author{Mikko Harju}
\institute{Taiste}

\begin{document}

\begin{frame}
\titlepage
\end{frame}

\begin{frame}
    \frametitle{About me}
    \begin{itemize}
        \item I'm Mikko Harju, Technology Director at Taiste
        \pause
        \item Python user since 2008
        \pause
        \item Functional programming enthusiast
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Agenda}
    \begin{itemize}
        \item We'll look slightly at \emph{threading} and more at \emph{processes} and how do they differ when
            implementing concurrency in Python.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Threads}
    \begin{itemize}
        \item Threads are the smallest unit of processing that can be scheduled (by an operating system).
        \pause
        \item They live within the process boundary, sharing the memory space.
        \pause
        \item This makes it trivial to transfer information from one thread to another.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Threads}
    \begin{itemize}
        \item To prevent problems when writing data from multiple threads to a shared state variable we need to
            introduce different kinds of \emph{locking mechanisms}.
        \pause
        \item Possibilities include e.g. mutexes, semaphores and critical sections.
        \pause
        \item If the threads only access the data in a read-only way, there is no need for locking.
        \pause
        \item This is called Shared-nothing -approach. Erlang has this with its ''lightweight processes``.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{GIL}
    \begin{itemize}
        \item GIL is Python's locking mechanism to ensure that threads co-operate nicely with non-thread safe constructs 
        \pause
        \item This is done by locking down the interpreter by giving exclusive access to one thread at a time.
        \pause
        \item This effectively means that only one CPU bound thread task is actually doing anything useful in one
            python interpreter process at a time.
        \pause
        \item When doing I/O, the interpreter can release the lock. The interpreter also has periodic checks to go along
            with this to make it possible to parallelize CPU bound threads.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{GIL}
    \begin{itemize}
        \item When we add more processors (or cores) to the mix, things get more complicated.
        \pause
        \item N threads can be scheduled simultaneously on N processors, making them all compete over the GIL. Nice.
        \pause
        \item So really, threads are not the right way to go in Python.
        \pause
        \item There are maybe some use cases where they might come in handy, where the problem is more I/O bound than CPU
            bound and there is an urgent need to be contained inside a single interpreter.
        \pause
        \item But let us concentrate on the more fruitful of doing real multiprocessor concurrency on Python: \emph{processes}
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Processes}
    \begin{itemize}
        \item Processes are OS backed construct. A separate python interpreter is run on each process.
        \pause
        \item Each process has its own memory space, stack, registers and that kind of stuff.
        \pause
        \item Scheduling is performed by the operating system.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Let's do this!}
    \begin{itemize}
        \item Nothing beats practice, so let's do parallel image processing with PIL using the multiprocessing package
            and see what we come up with. 
    \end{itemize}
\end{frame}

\end{document}

